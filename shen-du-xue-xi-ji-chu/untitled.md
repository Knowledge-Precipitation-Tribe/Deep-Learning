# 神经网络基本工作原理

## 什么是神经元

对于单个神经元来说，一般结构如下：



其中包括以下几个模块：

* 输入 input
* 权重 weights
* 偏置 bias
* 求和计算 sum
* 激活函数 activation

从单个神经元推广到更复杂的神经网络的模型，都少不了以上的几个模块，下面我们分别介绍一下以上的几个模块。

### 输入input

神经元的输入也就是我们要喂给神经元什么数据，如上一小节中提到的房子信息，对于输入神经元的数据，一般是会有好多个特征，如上图中的$$x_1,x_2,x_3$$可以分别代表房子面积，房子采光好不好，房子是不是挨着街道。

### 权重weights

权重代表输入数据中每个特征所占的比重，例如房子价格肯定会与房子面积占有很大关系，那么房子面积所对应的权重$$w_1$$就会相对大。

### 偏置bias

对于偏置的解释有很多种，但是我较为认同的是偏置代表一种神经元的临界状态。一定是输入信号大于某个临界值时，神经元细胞才会处于兴奋状态，这个偏置$$b$$实际就是那个临界值。

### 求和计算sum

$$
Z=w_1 · x_1+w_2⋅x_2+w_3⋅x_3+b
$$

如果将上面公示转变为矩阵运算则表示为

$$
Z = W · X + b
$$

### **激活函数activation**

经过求和之后，我们想要知道有多少信息是要传递下去饿，这个可以通过激活函数来控制。

$$
A=σ(Z)
$$

#### 为什么需要激活函数

看以下的例子：

$$
Z1=X⋅W1+B1
$$

$$
Z2=Z1⋅W2+B2
$$

$$
Z3=Z2⋅W3+B3
$$

展开：

$$
\begin{aligned}
Z 3 &=Z 2 \cdot W 3+B 3 \\
&=(Z 1 \cdot W 2+B 2) \cdot W 3+B 3 \\
&=((X \cdot W 1+B 1) \cdot W 2+B 2) \cdot W 3+B 3 \\
&=X \cdot(W 1 \cdot W 2 \cdot W 3)+(B 1 \cdot W 2 \cdot W 3+B 2 \cdot W 2+B 3) \\
&=X \cdot W+B
\end{aligned}
$$

$$Z1,Z2,Z3$$分别代表三层神经网络的计算结果。最后可以看到，不管有多少层，总可以归结到$$X·W+B$$的形式，这和单层神经网络没有区别。

如果我们不运用激活函数的话，则输出信号将仅仅是一个简单的线性函数。线性函数一个一级多项式。线性方程是很容易解决的，但是它们的复杂性有限，并且从数据中学习复杂函数映射的能力更小。一个没有激活函数的神经网络将只不过是一个线性回归模型罢了，不能解决现实世界中的大多数非线性问题。

没有激活函数，我们的神经网络将无法学习和模拟其他复杂类型的数据，例如图像、视频、音频、语音等。这就是为什么我们要使用人工神经网络技术，诸如深度学习，来理解一些复杂的事情，一些相互之间具有很多隐藏层的非线性问题。

## 小结

* 一个神经元可以有多个输入。
* 一个神经元只能有一个输出，这个输出可以同时输入给多个神经元。
* 一个神经元的$$w$$的数量和输入的数量一致。
* 一个神经元只有一个$$b$$。
* $$w$$和$$b$$有人为的初始值，在训练过程中被不断修改。
* $$A$$可以等于$$Z$$，即激活函数不是必须有的。
* 一层神经网络中的所有神经元的激活函数必须一致。



