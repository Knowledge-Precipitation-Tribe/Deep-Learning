# 数据集的处理方式

## 交叉验证 Cross validation

### 传统的机器学习

在传统的机器学习中，我们经常用交叉验证的方法，比如把数据分成10份，**V1-V10，其中V1-V9**用来训练，V10用来验证。然后用V2~V10做训练，V1做验证......如此我们可以做10次训练和验证，大大增加了模型的可靠性。

这样的话，验证集也可以做训练，训练集数据也可以做验证，当样本很少时，这个方法很有用。

### 深度学习

那么深度学习中的用法是什么呢？

比如在神经网络中，训练时到底迭代多少次停止呢？或者我们设置学习率为多少何时呢？或者用几个中间层，以及每个中间层用几个神经元呢？如何正则化？这些都是超参数设置，都可以用验证集来解决。

一般**使用损失函数值小于门限值做为迭代终止条件**，对于实际应用中的问题，没有先验的门限值可以参考，如何设定终止条件？此时，我们可以用验证集来验证一下准确率，假设只有90%的准确率，可能是局部最优解。这样我们可以继续迭代，寻找全局最优解。

举个例子：一个BP神经网络，我们无法确定隐层的神经元数目，因为没有理论支持。此时可以按下面的示意图这样做。

![](../../.gitbook/assets/image%20%286%29.png)

1. 随机将训练数据分成K等份（通常建议K=10），得到$$D_0, D_1, D_{10}$$；
2. 对于一个模型M，选择$$D_9$$为验证集，其它为训练集，训练若干轮，用$$D_9$$验证，得到误差$$E$$。再训练，再用$$D_9$$测试，如此N次。对N次的误差做平均，得到平均误差；
3. 换一个不同参数的模型的组合，比如神经元数量，或者网络层数，激活函数，重复2，但是这次用$$D_8$$去得到平均误差；
4. 重复步骤2，一共验证10组组合；
5. 最后**选择具有最小平均误差的模型结构**，用所有的$$D_0$$~$$D_9$$再次训练，成为最终模型，不用再验证；
6. 用测试集测试。

## 留出法 Hold out

使用交叉验证的方法虽然比较保险，但是非常耗时，尤其是在大数据量时，训练出一个模型都要很长时间，没有可能去训练出10个模型再去比较。

在深度学习中，有另外一种方法使用验证集，称为留出法。亦即**从训练数据中保留出验证样本集，主要用于解决过拟合情况，这部分数据不用于训练。如果训练数据的准确度持续增长，但是验证数据的准确度保持不变或者反而下降，说明神经网络亦即过拟合了，此时需要停止训练，用测试集做最终测试。**

关于三者的比例关系，在传统的机器学习中，三者可以是6:2:2。在深度学习中，一般要求样本数据量很大，所以可以给训练集更多的数据，比如8:1:1。

如果有些数据集已经给了你训练集和测试集，那就不关心其比例问题了，只需要从训练集中留出10%左右的验证集就可以了。

